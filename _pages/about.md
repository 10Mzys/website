---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am now a Postdoctoral Fellow in the Department of Statistics at Harvard University, under the supervision of [Prof. Zheng (Tracy) Ke](https://zke.fas.harvard.edu/). I obtained my Ph.D. degree in Statistics at UC Davis, where I was fortunate to be co-advised by [Prof. Krishna Balasubramanian](https://sites.google.com/view/kriznakumar/) and [Prof. Wolfgang Polonik](https://www.stat.ucdavis.edu/~polonik/). Before coming to UC Davis, I received my Bachelor's degree in Math at Fudan University, where I was advised by [Prof. Lei Shi](https://mastone1983.github.io/).

My current research interests lie at the intersection of three domains: statistical inference, machine learning, and generative models. To be precise, I focus on understanding the theoretical principles of:
* Nonparametric Statistical Inference and Estimation,
* Statistical Perspectives on Dense Associative Memories (Hopfield networks),
* Statistical Network analysis,
  
with their applications to uncertainty quantification, reinforcement learning, causal inference, and econometrics.

Recent News
======
* Excited to announce I will be co-organzing a workshop ["New Frontiers in Associative Memory"](https://nfam2026.amemory.net/) at ICLR 2026.
* Our recent work [Dense Associative Memory with Epanechnikov energy](https://arxiv.org/abs/2506.10801v1) has been accepted to NeurIPS with Spotlight! In this work, we proposed a novel energy function for Dense Associative Memory (DenseAM) networks, the log-sum-ReLU (LSR), inspired by optimal kernel density estimation, that solves the memorization-generation trade-off in DAMs while showing a unique ability to generate abundant additional local minima (we call them `emergent memory').
* I am invited to give a talk on `From Smooth to Nonsmooth: Minimax Optimal Regression with Laplacian Eigenmaps' at [SIAM UQ26 minisymposium "Probabilistic Manifold Learning and Deep Embeddings for Uncertainty Quantification"](https://www.siam.org/conferences-events/siam-conferences/uq26/), Mar 2026.
* I am invited to give a talk on `Smooth Dynamic Network Analysis' at the [JSM2025](https://ww2.amstat.org/meetings/jsm/2025/), Aug 2025. 
* I will give a talk titled `On the nonasymptotic statistical inferences via stabilization theory of Gaussian approximation bounds' at the [22nd INFORMS Applied Probability Society Conference](https://informs-aps.isye.gatech.edu/program) at Georgia Institute of Technology from June 30th to July 3rd, 2025.
* Our recent work [Gaussian and Bootstrap Approximation for Matching-based Average Treatment Effect Estimators](https://arxiv.org/abs/2412.17181) is now avaible on Arxiv! Taking ATE as an example, we provide a general framework for non-asymptotic statistical inference via a local geometric concept called `stabilization'.
* I joined the Department of Statistics, Harvard University, on September 1, 2024, as a Postdoctoral Fellow.
